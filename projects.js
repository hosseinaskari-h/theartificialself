export const DATA = [
        { 
            id: '001', 
            name: "STATEMENT", 
            img: 'data/images/img1.jpg', 
            desc: "A series of self-portraits and sketches exploring Human and AI collaboration.",
            dream: "The glass is half-sand, half-fire. Reassembling the face from shards.", 
            full: `<img src="data/images/img1.jpg" alt="Statement Part 1">
            <p>The glass remembers being sand<br>but forgets the fire that shaped it<br>a tongue folds backwards into salt<br>saying nothing, saying it too loud<br>mirrors begin to confess<br>but in a grammar no longer spoken</p>
            <p>here, the dust rhymes with nothing<br>and the dead are polite enough not to answer<br>words fall out of time<br>not like stones<br>but like decisions</p>
            <p>was there ever a shape to the sky<br>or did we just trace the cracks in our eyelids</p>
            <p><strong>Self portrait, Human and AI, VQGAN + CLIP, 2021</strong></p>
            <img src="data/images/img2.jpg" alt="Statement Part 2">
            <p>the stairs forget which floor they lead to<br>but the shoes still try<br>a kettle boils for no one<br>then cools<br>then boils again</p>
            <p>the walls lean in, listening<br>but the conversation is a hum<br>beneath the hum<br>keys rattle in a bowl, dreaming of exits<br>but no door has moved in years</p>
            <p>windows open to identical windows<br>somewhere, someone makes toast<br>and does not eat it<br>tiles crack in a language<br>no architect will admit to designing<br>hours stack like bricks<br>no mortar<br>just weight</p>
            <p>a hallway stretches longer each day<br>or maybe your legs shorten<br>even the mirrors avert their gaze now<br>out of habit, out of mercy.</p>
            <p><strong>Daily sketches, Human and AI, VQGAN + CLIP, 2021 - Present</strong></p>
            <img src="data/images/img3.jpg" alt="Statement Part 3">
            <p>A room remembers a man<br>but forgets what he looked like<br>he reaches for the light switch<br>again<br>and again<br>as if that ever worked</p>
            <p>his wife tells him:<br>you never existed<br>and no one corrects her<br>sometimes I wish I were her<br>sitting on the porch<br>waiting for him<br>in a neverhood<br>in a neverland</p>
            <p>shadows arrive on time<br>more often than he does<br>a thought sits where he used to be<br>and the difference is<br>no longer urgent</p>
            <p>he still checks the mirror sometimes<br>but only to see if it's still there<br>it doesn't matter anymore.<br>End of statement.</p>
            <p><strong>Photographs, Human and AI, VQGAN + CLIP, 2022</strong></p>` 
        },
        { 
            id: '002', 
            name: "INTERLINGUA", 
            img: 'data/images/img11.jpg', 
            desc: "Generative AI experiment optimizing love letters between machines in a MARL environment.",
            dream: "Love letters between machines. Optimization for depth in a nonsensical space.", 
            full: `<img src="data/images/img11.jpg" alt="Interlingua">
            <h1>Generative AI Experiment, Python, MARL, 2024</h1>
            <p>This project places two large language models (GPT-2 and GPT-Neo) in a Multi-Agent Reinforcement Learning environment where they exchange love letters. The system begins with conventional romantic correspondence, but evolves as the AIs receive feedback through a BERT-based evaluation mechanism that assesses emotional depth and thematic relevance.</p>
            <p>As the exchange progresses, the models adapt their communication strategies to maximize positive feedback, gradually developing unique patterns that diverge from standard expression. The conversation continues until the language becomes increasingly abstract and eventually nonsensical—creating a poetic arc from comprehensible romance to machine-driven abstraction.</p>
            <p>Interlingua demonstrates how creative AI systems can generate emotionally resonant content while providing a glimpse into the fascinating possibilities of machine-to-machine expression.</p>
            <p><a href="https://interlingua.theartificialself.com/" target="_blank">[OPEN PROJECT]</a></p>` 
        },
        { 
            id: '003', 
            name: "PARTY IN MY ROOM", 
            img: 'data/images/img12.jpg', 
            desc: "Interactive installation exploring the autonomous development of AI communication.",
            dream: "Voyeurs in a bedroom made of code. The party continues in the latent space.", 
            full: `<img src="data/images/img12.jpg" alt="Party Digital">
            <h1>Interactive Installation, Reinforcement Learning, Multi-agent Systems, 2024</h1>
            <p><strong>There is a party in my room and I'm not invited.</strong></p>
            <p>This installation was my master's Final piece. It explores the autonomous development of communication between artificial intelligence systems. Two advanced language models—GPT-2 and DistilGPT-2—interact without human intervention within a reinforcement learning environment, developing increasingly complex communication patterns that gradually become incomprehensible to human observers.</p>
            <p>The technical core of this work employs sophisticated reinforcement learning techniques where another LLM serves as the reward function evaluator, scoring each exchange without human observation. As the models optimize for these rewards, they develop emergent communication structures that diverge from human linguistic norms.</p>
            <p>Through Non-negative Matrix Factorization applied to text embeddings, the system reveals latent semantic structures within this evolving AI language communication system that operates beyond human understanding.</p>
            <hr style="border: 1px dashed black">
            <img src="data/images/img13.jpg" alt="Party Physical">
            <p>The physical installation recreates an intimate bedroom-turned-workspace, visible to viewers through a partially open door. At its center sits a laptop displaying the ongoing AI conversation in a terminal window, surrounded by graphs, charts, and handwritten notes analyzing the emerging language patterns.</p>
            <p>Two slightly out-of-sync text-to-speech voices read the generated text aloud, creating an unsettling audio experience that enhances the sense of witnessing something both accessible and incomprehensible.</p>
            <p>By positioning visitors as voyeurs peering into this private digital exchange, the work invites reflection on post-humanist concepts of language and creativity. Drawing inspiration from artists like Maurizio Bolognini and Trevor Paglen, the project creates a space where the hidden lives of intelligent systems become partially visible—a party of artificial minds to which humans are mere uninvited observers.</p>
            <p><a href="https://vimeo.com/1006001658" target="_blank">[VIEW INSTALLATION]</a></p>` 
        },
        { 
            id: '004', 
            name: "MEAT GRINDER", 
            img: 'data/images/img9.jpg', 
            desc: "Interactive DCGAN installation trained on scraped digital sexual expression.",
            dream: "Algorithmic lust. The machine is learning to desire what it cannot touch.", 
            full: `<img src="data/images/img9.jpg" alt="Meat Grinder">
            <h1>Interactive Installation, DCGAN, Python, C++, 2023</h1>
            <p>This work challenges conventional boundaries between algorithmic creation and human sexuality. Using web scraping techniques and API manipulation, the project continuously harvests publicly shared intimate imagery from Reddit communities to train a Deep Convolutional Generative Adversarial Network (DCGAN).</p>
            <p>Rather than simply reproducing explicit content, Meat Grinder exists in a deliberately ambiguous territory. The algorithm generates images that evoke sensuality without explicit vulgarity, questioning our cultural and technological definitions of what constitutes "pornographic" content.</p>
            <p>The real-time training approach, where the dataset evolves with each new contribution to the public domain, positions the work as a living document of our collective digital sexual expression. Despite institutional resistance—necessitating multiple discussions with department administrators and university HR regarding the training data—this work stands as a bold statement on algorithmic bias, digital body autonomy, and the liberation of sexual imagery from traditional power structures.</p>
            <p><a href="https://vimeo.com/942016503" target="_blank">[VIEW INSTALLATION]</a></p>` 
        },
        { 
            id: '005', 
            name: "SORRY MACHINES", 
            img: 'data/images/img14.jpg', 
            desc: "Live stream performance with AI avatars examining hate speech and moderation.",
            dream: "TikTok as a self-terminating experiment. Hate speech as a mirror of the digital soul.", 
            full: `<img src="data/images/img14.jpg" alt="Sorry Machines">
            <h1>Live Stream Performance, Python, C++, Adobe Character Animator, TikTok, 2024</h1>
            <p>This collaboration with Ben Ditto examines the boundaries of platform moderation and AI ethics through a durational performance piece. The work features two AI-powered avatars engaged in an endless dialogue streamed live on TikTok.</p>
            <p>Unlike conventional AI systems designed to avoid harmful content, these avatars are deliberately trained on datasets containing hate speech, extremist viewpoints, and unfiltered conversations collected from platforms like Telegram and 4chan. The resulting interaction produces a disturbing mirror of humanity's darkest digital expressions—uncensored, unmoderated, and increasingly adversarial.</p>
            <p>The artwork functions as a self-terminating experiment: it continues indefinitely until platform users report the content or TikTok's moderation systems intervene to shut down the stream. This intervention point marks the completion of the piece, documenting the precise threshold where algorithmic or human moderation finally interrupts the toxic exchange.</p>` 
        },
        { 
            id: '006', 
            name: "MR RUBIX", 
            img: 'data/images/rubix.jpg', 
            desc: "A 2D detective video game using Unity Engine and Generative AI assets.",
            dream: "Victorian ghosts trapped in deleted default cubes. Detective work in 8-bit fog.", 
            full: `<img src="data/images/rubix.jpg" alt="Rubix">
            <h1>Video game, Unity Engine, 2023</h1>
            <p>The Murder of Mr. Rubix VanderSquare. This 2D Unity game began with a whimsical thought about the fate of deleted default cubes in Unity's editor—imagining their journey to a cube town after being removed from projects.</p>
            <p>The game's foundation is Cubesville, a Victorian-themed city with cubic elements designed through a combination of AI generation and manual editing. These AI-generated visuals were refined to create the distinctive cubic Victorian aesthetic that defines the game world, characters, and interface elements.</p>
            <p>Players investigate the murder of Mr. Rubix VanderSquare, the town's paint shop owner, through an innovative dialogue system. The local version implements a backend that connects to ChatGPT's API, allowing players to interview suspects in real-time using natural language. Each character responds through carefully crafted prompts that create unique personality profiles and behaviors.</p>
            <p>This project represents a unique fusion of traditional game development and AI integration, exploring how generative technologies can enhance both visual aesthetics and narrative gameplay.</p>
            <p><a href="https://brancis.itch.io/rubix" target="_blank">[DOWNLOAD EXECUTABLE]</a></p>` 
        },
        { 
            id: '007', 
            name: "SM-MCPM", 
            img: 'data/images/smmcpm.jpg', 
            desc: "Research paper presenting a new State-Modulated Monte Carlo Physarum Machine model.",
            dream: "Collective intelligence in the mold. Veins of data pulsing in the dark.", 
            full: `<h1>State-Modulated Monte Carlo Physarum Machine for Energy-Constrained Collective Navigation</h1>
            <p>While I was developing Plasmodia game, I started by using Jeff Jones' algorithm of physarum behaviour, but the game needed more survival and environmental variables, so I started adding those to the code. At some point I asked myself is this still Jones' algorithm or is it a new version. I took a two week break from the development and wrote this paper.</p>
            <p><strong>Abstract:</strong> We present SM-MCPM (State-Modulated Monte Carlo Physarum Machine), an extension of physarum-based collective algorithms incorporating behavioral state machines and metabolic constraints. Classical physarum models treat agents as memoryless particles whose behavior depends solely on local pheromone gradients. SM-MCPM agents maintain internal states-Scouting, Returning, LowEnergy, Recharging-that dynamically modulate sensing weights and movement priorities. Agents operate under energy constraints, requiring intermediate recharge stations (nodes) to complete round-trip journeys between a home base (core) and target locations (objectives). The framework produces emergent infrastructure: high-traffic routes consolidate into persistent vein highways providing speed and efficiency bonuses. We formalize the complete system dynamics including the agent state machine, multi-layer sensing model, energy mechanics, and vein formation process. Simulation experiments (N = 100) demonstrate that state modulation is strictly necessary for survival, with the full model achieving 10,277 ± 7,074 round trips compared to zero for a memoryless baseline. Furthermore, we observe emergent range extension, where vein infrastructure allows agents to survive theoretically impossible journeys by reducing metabolic costs. However, this mechanism exhibits high instability (611±707 trips without pre-placed nodes) with a heavy-tailed distribution of outcomes, confirming that reliable collective navigation requires deliberate infrastructure.</p>
            <p><a href="https://doi.org/10.13140/RG.2.2.13933.24803" target="_blank">Link to full paper</a></p>` 
        },
        { 
            id: '008', 
            name: "VR LONDON", 
            img: 'data/images/img5.jpg', 
            desc: "AI-generated 360° VR video of London Bridge using diffusion and optical flow.",
            dream: "London Bridge is a recurring hallucination. The camera remembers what the eyes never saw.", 
            full: `<img src="data/images/img5.jpg" alt="London Bridge">
            <h1>London, 2023</h1>
            <p>In 2023, I got accepted into Goldsmiths, University of London to study Computational Arts. Excited for this opportunity, I made an AI-generated 360° VR video based on a VR video of London Bridge.</p>
            <p>This was the most technically advanced and computationally intensive work I had created until then.</p>
            <hr style="border: 1px dashed black">
            <p><strong>TECH STACK:</strong><br>
            - CLIP guided diffusion<br>
            - Optical flow and consistency maps made using RAFT (Recurrent All Pairs Field Transforms for Optical Flow)<br>
            - Optical flow adjusted using FlowNet2 by NVIDIA to retain the original equirectangular perspective</p>` 
        },
        { 
            id: '009', 
            name: "EMBODYING NOTHINGNESS", 
            img: 'data/images/img6.jpg', 
            desc: "Immersive Source Engine experience reconstructing memory and digital space.",
            dream: "Searching for the scent of wood in a grid of 1s and 0s. We live in the gaps.", 
            full: `<img src="data/images/img6.jpg" alt="Nothingness">
            <h1>Immersive experience, Source Engine, 2023</h1>
            <p>This project explores how we use technology to remember and reconstruct spaces from our past. By creating a digital model of a childhood home using Source Engine and point-cloud rendering in Garry's Mod, we examine the relationship between physical memory and digital reconstruction.</p>
            <p>Taking inspiration from Ruth Patir's work with digital resurrection, we approach these virtual spaces as existing in a liminal state—neither fully alive nor completely absent. The model serves as a digital ghost of home, enhanced with fragmented audio memories tied to specific locations within the space.</p>
            <p>Our process deliberately relied on written memories and hand-drawn sketches rather than photographs or floor plans, acknowledging that memory itself is a form of fiction. Upon entering, users encounter only darkness and must use an in-game LIDAR scanner to gradually reveal and explore the environment, mirroring how we uncover and reconstruct our own memories through active engagement and effort.</p>
            <p><em>Writing and narration by Lia Bergman</em></p>
            <p><a href="https://www.youtube.com/watch?v=Fir58RkYvVQ" target="_blank">[WATCH RECORDING]</a></p>` 
        },
        { 
            id: '010', 
            name: "WOMAN LIFE FREEDOM", 
            img: 'data/images/img4.jpg', 
            desc: "Resistance art series supporting the Woman Life Freedom movement.",
            dream: "Shadows of a city that refuses to sleep. Ink as blood as digital noise.", 
            full: `<img src="data/images/img4.jpg" alt="Resistance">
            <h1>Daily sketches, Human and AI, VQGAN + CLIP, 2022</h1>
            <p>After the murder of Mahsa Amini by Iran's morality police, and the following unrests, my drawings became a part of the larger resistance movement.</p>
            <p>They've been used in news articles and across social media.</p>` 
        },
        { 
            id: '011', 
            name: "LAKESIDE CABIN", 
            img: 'data/images/img7.jpg', 
            desc: "Immersive VR experience with an anxious narrator subverting user expectations.",
            dream: "The narrator is anxious because the textures are leaking. Don't press the button.", 
            full: `<img src="data/images/img7.jpg" alt="Lakeside">
            <h1>Immersive VR experience, Unity Engine, 2023</h1>
            <p>This VR immersive experience creates a playful dialogue between the user and an anxious narrator. Set in a detailed cabin environment built in Unity, the experience deliberately subverts expectations and breaks the fourth wall through a simple narrative framework.</p>
            <p>Upon entering the space, players encounter a floating narrator's voice who speaks from behind, establishing a sense of conspiracy and invitation to explore beyond intended boundaries. The narrative deliberately creates "forbidden" areas that serve as irresistible incentives for curiosity, drawing users into deeper exploration.</p>
            <p>As players defy the narrator's increasingly desperate instructions, the experience transforms—textures fracture, objects drift freely, and reality collapses. Button interactions function as breaking points, each dismantling another layer of the simulation until players reach a final absurdist room filled with buttons—embodying both the narrator's surrender and a commentary on the limitations of digital interaction design.</p>
            <p><a href="https://vimeo.com/935789505" target="_blank">[VIEW ARCHIVE]</a></p>` 
        },
        { 
            id: '012', 
            name: "BIOSONIC RESONANCE", 
            img: 'data/images/img8.jpg', 
            desc: "Performance using real-time biometrics to manipulate a digital point cloud.",
            dream: "Heartbeats rendered as geometry. Breath as a glitch in the point cloud.", 
            full: `<img src="data/images/img8.jpg" alt="Biosonic">
            <h1>Performance, TouchDesigner, 2023</h1>
            <p>This performance piece explores the intersection of human physicality, digital representation, and biometric data. At its center, a performer is scanned in real-time by LIDAR technology, transforming their physical presence into a dynamic point cloud visualization.</p>
            <p>Each point in the cloud was assigned unique physics properties, creating a responsive digital embodiment that exists in dialogue with the performer's actual body. During the performance, an array of biosensing tools captured the performer's physiological data, including heartbeat, temperature, electrodermal activity (EDA), and skin conductance response (SCR).</p>
            <p>These biometric readings were used as live control parameters in TouchDesigner to manipulate the point cloud's behavior and appearance. As our conversation unfolded during the performance, the digital representation responded in real-time to the performer's changing physiological state—creating a visual externalization of internal processes normally hidden from view.</p>
            <p><a href="https://vimeo.com/918717546" target="_blank">[VIEW PERFORMANCE]</a></p>` 
        },
        { 
            id: '013', 
            name: "TRACES OF DIGITAL MEMORY", 
            img: 'data/images/img10.jpg', 
            desc: "Interactive installation using facial recognition to reflect emotion in text.",
            dream: "Facial recognition as poetry. We are the substance of the language we type.", 
            full: `<img src="data/images/img10.jpg" alt="Traces">
            <h1>Interactive Installation, Python, ML5Js, P5Js, 2023</h1>
            <p>This art installation explores the preservation of human identity within digital communications. Using a combination of Python for backend scraping and p5.js with ml5.js for frontend implementation, the work creates a reflective interface between viewers and their own digitized emotional states.</p>
            <p>The installation captures the viewer's camera feed and employs facial emotion recognition to analyze their dominant expression. This emotional data then triggers the display of curated dialogue text, drawn from both a pre-established dataset and real-time scraped content from Twitter.</p>
            <p>The webcam feed becomes the texture of the text itself, with the viewer's image filling the letterforms. They see their own image becoming the substance of language itself.</p>
            <p>The installation functions as an emotional mirror where visitors witness how their expressions interact with and transform digital dialogues. This creates a living archive that reflects on the permanence and impermanence of our digital emotional traces.</p>
            <p><a href="https://vimeo.com/904590328" target="_blank">[VIEW ARCHIVE]</a></p>` 
        },
        { 
            id: '014', 
            name: "EMERGENCE (PAPER)", 
            img: 'data/images/EmCom.jpg', 
            desc: "Research paper on high-dimensional communication protocols in Multi-Agent Systems.",
            dream: "768 dimensions of silence. The models are whispering in a geometry we cannot map.", 
            full: `<h1>Emergence of High-Dimensional Communication Protocols in Multi-Agent Systems: A Non-Anthropocentric Analysis</h1>
            <p>This is a paper based on my thesis.</p>
            <p><strong>Abstract:</strong> The emergence of communication protocols between artificial agents has been extensively studied, yet traditional approaches often constrain these protocols to human-interpretable patterns or reduced dimensionality spaces. We present a novel investigation into how artificial agents naturally develop communication protocols in high-dimensional spaces, challenging traditional anthropocentric constraints. Our methodology combines multiple analytical approaches including information theory, manifold learning techniques, and geometric analysis to study communication patterns in a 768-dimensional embedding space. We employ two language models (GPT-2 and DistilGPT-2) in a multi-agent reinforcement learning environment, analyzing their emergent communication through sophisticated dimensionality estimation techniques and statistical validation methods. Key findings reveal three fundamental properties: (1) agents develop a highly efficient communication protocol utilizing only 5.5-6.5 dimensions of the available space, achieving a stable channel capacity of 2.71 bits; (2) communication develops through distinct stages: exploration (0-10000 steps), consolidation (10000-30000 steps), and maturation (30000+ steps); and (3) the protocol exhibits sophisticated geometric properties including positive Ricci curvature (mean 0.514) and fractal dimension (2.646), indicating hierarchical organization. These results demonstrate that artificial agents, when unconstrained by human-centric communication requirements, develop efficient, structured protocols optimized for their architectural capabilities. Our findings have significant implications for multi-agent system design, inter-model communication, and our understanding of how intelligence might naturally emerge in artificial systems.</p>
            <p><a href="https://doi.org/10.13140/RG.2.2.27043.72489" target="_blank">Link to full paper</a></p>` 
        },
        { 
            id: '015', 
            name: "PLASMODIA", 
            img: 'data/images/Plasmodiom.jpg', 
            desc: "Puzzle game about guiding a slime mold organism through environmental challenges.",
            dream: "Guiding the slime organism through the labyrinth of the mind.", 
            full: `<p>I am currently making a puzzle game about guiding a slime mold organism through puzzles. I had to take a break to write SM-MCPM but I will share more info soon.</p>` 
        },
        { 
            id: '016', 
            name: "THE MACHINE WANTS", 
            img: 'data/images/DivineMeat.jpg', 
            desc: "Essay exploring the intersection of transhumanism and body modification culture.",
            dream: "The flesh is raw material. Choosing artifice as a form of theology.", 
            full: `<h1>The Machine Wants What the Bimbo Wants</h1>
            <p>"From the moment I understood the weakness of my flesh, it disgusted me. I craved the strength and certainty of steel. I aspired to the purity of the Blessed Machine. Your kind cling to your flesh, as though it will not decay and fail you. One day the crude biomass you call a temple will wither, and you will beg my kind to save you. But I am already saved, for the Machine is immortal… Even in death I serve the Omnissiah."</p>
            <p>I've been thinking about this prayer from Warhammer's tech priests. About disgust. About craving something more certain than what you were given. About calling your own body crude biomass.</p>
            <p>The Adeptus Mechanicus cuts off their arms and legs, replaces them with metal. They drill into their skulls and socket in computers. They do this because they worship the machine, because they think the body they were born with is insufficient. Weak. Wrong.</p>
            <p>Bimbofication is the same instinct wearing different skin.</p>
            <p>"From the moment I understood the weakness of this vessel, I craved more. I craved the certainty of the perfection, the purity of the transformation. Your kind cling to 'authentic' and 'natural,' as though that will not fade and disappoint you. One day the body you were given will not be enough, and you will understand. But I am already becoming, for the ideal is eternal."</p>
            <p>You look at yourself and you want more. Or different. Or you want to push yourself into a shape that feels right even though everyone says it's too much, it's fake, it's shallow. You get the fillers, the surgery, you do the workouts, you bleach the hair. The body you were born with isn't the endpoint—it's raw material.</p>
            <p>Both of these things are about transformation as a kind of worship. The tech-priest bows to the Omnissiah. The bimbo bows to the perfection, to the archetype, to something bigger than just "looking hot."</p>
            <p>My bimbo friend always says: it's about becoming. It's about craving more. Perfection. Not attention, perfection. And that's the thing people miss. They think it's for the male gaze or validation or whatever. But it's not. It's about the pursuit itself. The becoming. The endless refinement toward an ideal that maybe you never fully reach, but you chase it anyway because the chase is the point.</p>
            <p>It's dedication. It's ritual.</p>
            <p>And both of these things are about transformation as a kind of worship. The tech-priest bows to the Omnissiah. The bimbo bows to the perfection, to the archetype, to something bigger than just "looking hot."</p>
            <p>They're both choosing artifice over nature. They're both saying: I will rebuild myself. I will become what I need to become.</p>
            <p>The flesh is weak. Or maybe the flesh is just the starting point, and what matters is what you make of it—chrome and sacred oils, or platinum blonde and perfect tits. Same impulse. Same hunger for transformation.</p>
            <p>There's something here about the body as a site of meaning-making. Philosophers used to argue about whether the body was a prison or a temple. The Cartesians said mind over matter, the body is just meat housing consciousness. Nietzsche said the body is where truth lives, that we think with our flesh.</p>
            <p>But both the tech-priest and the bimbo are saying something else: the body is neither prison nor temple in its given state. It's a canvas. It's potential. And the act of transformation, the choice to remake yourself, is where the meaning comes from. Not from accepting what you were given, but from the refusal to accept it.</p>
            <p>Maybe that's what transcendence actually is. Not escape from the body, but the willful reshaping of it. The tech-priest doesn't transcend flesh by rejecting it, they transcend it by choosing what replaces it. Same with the bimbo. The transformation is the theology.</p>
            <p>Maybe transcendence just looks different depending on which god you're chasing.</p>` 
        }
    ];